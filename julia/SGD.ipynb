{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X_train, Y_train, X_test, Y_test, model_alpha):\n",
    "    clf = linear_model.Ridge(model_alpha)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    loss = np.sum((predictions - Y_test)**2)\n",
    "    return loss\n",
    "\n",
    "def lasso_regression(X_train, Y_train, X_test, Y_test, model_alpha):\n",
    "    clf = linear_model.Lasso(model_alpha)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    loss = np.sum((predictions - Y_test)**2)\n",
    "    return loss\n",
    "# https://stackoverflow.com/questions/35714772/sklearn-lasso-regression-is-orders-of-magnitude-worse-than-ridge-regression\n",
    "\n",
    "def stochastic_gradient_descent(ga_out):\n",
    "    Y = [ np.sum(v.fitness.values) for k,v in ga_out['history'].genealogy_history.items() ]\n",
    "    X = [ list(v.dtc.attrs.values()) for k,v in ga_out['history'].genealogy_history.items() ]\n",
    "    #ordered_attrs = set(ind.dtc.attrs.keys() for ind in ga_out['history'].genealogy_history[1])\n",
    "    ordered_attrs = list(ga_out['history'].genealogy_history[1].dtc.attrs.keys())\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(ordered_attrs)\n",
    "    le.classes_\n",
    "\n",
    "    X = np.matrix(X)\n",
    "    X,before = scale(X)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3)\n",
    "    sgd = SGDClassifier(penalty='l2', max_iter=1000, learning_rate='constant' , eta0=0.001  )\n",
    "\n",
    "    sgd = SGDRegressor(penalty='l2', max_iter=1000, learning_rate='constant' , eta0=0.001  )\n",
    "    sklearn.neural_network.MLPRegressor\n",
    "    dnn = MLPClassifier(hidden_layer_sizes=(len(X),len(Y) ), activation='relu',\n",
    "        solver='lbfgs', alpha=0.0001, batch_size='auto', learning_rate='constant',\n",
    "        learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True,\n",
    "        random_state=None, tol=0.0001, verbose=True, warm_start=False,\n",
    "        momentum=0.9, nesterovs_momentum=True, early_stopping=False,\n",
    "        validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08,\n",
    "        n_iter_no_change=10)\n",
    "    sgd.fit(X_train, Y_train)\n",
    "    dnn.fit(X_train, Y_train)\n",
    "    Y_pred = sgd.predict(X_test)\n",
    "    sklearn_sgd_predictions = sgd.predict(X_test)\n",
    "\n",
    "    losslasso = lasso_regression(X_train, Y_train, X_test, Y_test, 0.3)\n",
    "    lossridge = ridge_regression(X_train, Y_train, X_test, Y_test, 0.3)\n",
    "\n",
    "    print(sklearn_sgd_predictions)\n",
    "    print(ga_out['pf'][0].dtc.attrs)\n",
    "    delta_y = Y_test - sklearn_sgd_predictions\n",
    "    #pl.matshow(cm)\n",
    "    #pl.title('Confusion matrix of the classifier')\n",
    "    #pl.colorbar()\n",
    "    #pl.show()\n",
    "\n",
    "    return sgd, losslasso, lossridge\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
